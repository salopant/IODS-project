---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Week 2 results

This week I have learned how to do data wrangling with R. Also learned: 

- Function select (of library dplyr) applied with function one_of is handy in making a dataframe from a subset of features of original df. 

- Function colnames gives me a pointer to the column names. 

- Function filter can be applied to filtering those rows of dataframe that fulfill the given criteria

-ggplot with aes mappings is also useful: ggplot(learning2014, aes(col = gender, size = age, x = attitude, y = points))

- pairs draws an array of scatter plots

I also refreshed my knowledge of linear regression analysis and learned something new about model validation. Practical model validation can be done with graphical plots such as plotting the fitted values vs the corresponding residuals (the error between fit and real value), Normal QQ-plot (Theoretical Quantiles vs. Standardized residual) and Residuals vs. leverage. 

- diagnostic plot of a linear model with plot & argument which: plot(my_model2, which <- c(1, 2, 5))

- QQ plot reveals information about the normality of the errors

- Constant variance of error plot (fitted vs. residuals) should have no pattern

- Leverage: how much impact a single observation has (e.g. outliers)


## Useful links and resources
Data wrangling cheat sheet:
https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf

ggplot2 cheat sheet:
https://www.rstudio.com/wp-content/uploads/2016/11/ggplot2-cheatsheet-2.1.pdf

### Link to some videos
Regression analysis

https://player.vimeo.com/video/199820260

Model validation

https://player.vimeo.com/video/199820384

## Task

### Data wrangling part:
./data/create_learning2014.R

### Data analysis


#### Exercise data
This data is originally collected by a survey for an international survey of Approaches to Learning by Kimmo Vehkalahti 2014 - 2015. This is a modified  version of that data with data of three background questions (age, attitude, points) as such and the data of other questions grouped/compressed (average value of original factors) into three features covering deep, strategic and surface learning. 

The total number of respondents is 166, 110 female, 56 male. Number of features is 7.
```{r}
lrn2014 <- read.csv("./data/learn14.csv")
dim(lrn2014)
```


An example of typical values of individual respondents to all recorded  features can be seen here:
```{r}
head(lrn2014)
```
And a summary of each feature's variation and means:

```{r}
summary(lrn2014)
```

####Graphical representation of variations of the features:
Distribution of age with respect to gender shows that the number of men is lower than that of female and proportionally the difference is significant in class of 1 - 20 years. There are nearly no men of that age, in contrary to females. 

With feature of attitude the distribution is much narrower with men, also it is located (mean) in remarkably higher level than that of women.

```{r}
par(mfrow=c(1,2))
colors <- c("blue", adjustcolor("red", alpha.f = 0.5))
hist(lrn2014$Age[lrn2014$gender == "F"], main = "Age of respondents", xlab = "Age in years", col = colors[1])
hist(lrn2014$Age[lrn2014$gender == "M"],col = colors[2], add=TRUE)
legend("center", c("Female", "Male"), col=colors, lwd=5)

colors <- c("blue", adjustcolor("red", alpha.f = 0.5))
hist(lrn2014$Attitude[lrn2014$gender == "F"], main = "Attitude of respondents", xlab = "Attitude level", col = colors[1])
hist(lrn2014$Attitude[lrn2014$gender == "M"],col = colors[2], add=TRUE)
legend("center", c("Female", "Male"), col=colors, lwd=5)
```


From the pairwise scatterplots of the descriptive features of attitude, deep, stra, surf and points we can see that the features deep and surf might correlate negatively. As well, the attitude level and points seem to correlate positively.
```{r}
p <- pairs(lrn2014[3:7], col = lrn2014$gender, main = "Scatterplot between descriptive features")
par(xpd=TRUE)
legend(0,1.1, as.vector(unique(lrn2014$gender)), fill=c("black", "red"))
#legend("bottomright", fill = unique(iris$Species), legend = c( levels(iris$Species)))

```

The boxplots of this summary plot confirm the difference between the two genders with respect to the attitude (first row, third column). With feature surf there seems to be differnce in the distributions of the two genders implying that females tend to perform better with the questions measuring the surface knowledge factor (6,6). Similar, but smaller, effect can be seen with the factor of strategic knowledge (5,5).

The correlation coefficient calculated for features Attitude and Points show that they would correlate. The negative correlation seen in the scatterplot for the features stra and surf seems to be real even though the confidence interval almost covers the value zero.
```{r}
library(GGally)
library(ggplot2)

# create a more advanced plot matrix with ggpairs()
ggpairs(lrn2014, mapping = aes(col = gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))
```

### Linear regression
Let us next try if we can find a linear regression model to explain the variable Points. The previous plot suggests that variables Attitude, stra and surf could be useful in this.
```{r}
# create linear regression model with three explanatory variables to explain Points
model <- lm(Points ~ Attitude + stra + surf, data = lrn2014)
summary(model)
```
The coefficient for the feature Attitude is significant (p = 1.93e-08) but the two others not (stra: p = 0.12, surf: p=0.47). Let us first remove the variable surf from the model and try again:

```{r}
model <- lm(Points ~ Attitude + stra, data = lrn2014)
summary(model)
```

The value of stra is positive (~0.914), implying a positive correlation but it is not significant (p = 0.089). Generate one more model with only Attitude as explanatory feature:

```{r}
model <- lm(Points ~ Attitude, data = lrn2014)
summary(model)
```

This implies a linear model
$$
y = 0.353x + 11.637
$$
where $x$ is Attitude and $y$ is the exam points. Coeffient $\beta=0.353$ is significant with $p=4.12 * 10^{-9}$ and intercept $\alpha=11.637$ is significant with $p=1.95 * 10^{-9}$. Multiple R squared $R^2=0.1906$ implying that the variable Attitude (x) is able to explain about 19% of the variation of the dependent variable, exam points (y).  

The diagnostic plots of the linear model can be used to assess the validity of the model. The model is valid only if certain assumptions hold: linear dependence between the explanatory and dependent variables, normality of errors and independency of the errors and explanatory variables. Also, the validity of the model requires that no single observation should have a significant impact on the model.

These factors can be tested with:

- QQ plot to reveal information about the normality of the errors

- Constant variance of error plot (fitted vs. residuals) for independency between the explanatory variables and errors

- Leverage: how much impact a single observation has (e.g. outliers)
```{r}
par(mfrow = c(2,2))
plot(model, which <- c(1, 2, 5))
```

From these plots we can infer: 
- The plot Residuals vs. Fitted shows no clear pattern implying there is not dependency between the explanatory variables and the residual errors. 
- In the normal QQ-plot the data points follow closely the dotted linear diagonal implying that the errors are normally distributed.
- The leverage plot shows no single observation being visible separated from the set of points suggesting that there is no outliers 